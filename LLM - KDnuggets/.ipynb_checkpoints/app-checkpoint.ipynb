{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb76f2-39b6-4145-aa98-9fd8098f61af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "# !pip install langchain\n",
    "# !pip install langchain_community\n",
    "# ! pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64395551-56bb-4e29-a5f9-b83018fb7912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623e4d0b-05b0-4c62-a3c6-0ce01a24f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "def config():\n",
    "    load_dotenv()\n",
    "\n",
    "## os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9d94c50-2c28-4a68-817c-937bed0d572d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-09 18:38:54.054 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/juanfazzano/miniconda3/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-07-09 18:38:54.054 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary modules from the Streamlit and LangChain packages\n",
    "import streamlit as st\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Setting the title of the Streamlit application\n",
    "st.title('Simple LLM-App ðŸ¤–')\n",
    "\n",
    "# Creating a sidebar input widget for the OpenAI API key, input type is password for security\n",
    "openai_api_key = st.sidebar.text_input('OpenAI API Key', type='password')\n",
    "\n",
    "# Defining a function to generate a response using the OpenAI model\n",
    "def generate_response(input_text):\n",
    "    # Initializing the OpenAI model with a specified temperature and API key\n",
    "    llm = OpenAI(temperature=0.7, openai_api_key=openai_api_key)\n",
    "    # Displaying the generated response as an informational message in the Streamlit app\n",
    "    st.info(llm(input_text))\n",
    "\n",
    "# Creating a form in the Streamlit app for user input\n",
    "with st.form('my_form'):\n",
    "    # Adding a text area for user input with a default prompt\n",
    "    text = st.text_area('Enter text:', '')\n",
    "    # Adding a submit button for the form\n",
    "    submitted = st.form_submit_button('Submit')\n",
    "    # Displaying a warning if the entered API key does not start with 'sk-'\n",
    "    if not openai_api_key.startswith('sk-'):\n",
    "        st.warning('Please enter your OpenAI API key!', icon='âš ')\n",
    "    # If the form is submitted and the API key is valid, generate a response\n",
    "    if submitted and openai_api_key.startswith('sk-'):\n",
    "        generate_response(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8acab07-eb1b-402b-a564-9073ea06761a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook app.ipynb to script\n",
      "[NbConvertApp] Writing 1895 bytes to app.py\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.147:8502\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
      "\n",
      "`from langchain_community.llms import OpenAI`.\n",
      "\n",
      "To install langchain-community run `pip install -U langchain-community`.\n",
      "  warnings.warn(\n",
      "2024-07-09 18:39:04.035 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 589, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"/Users/juanfazzano/Documents/AI/AI-LINTI/LLM - KDnuggets/app.py\", line 70, in <module>\n",
      "    get_ipython().system(' jupyter nbconvert --to script app.ipynb')\n",
      "    ^^^^^^^^^^^\n",
      "NameError: name 'get_ipython' is not defined\n",
      "2024-07-09 18:39:38.462 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 589, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"/Users/juanfazzano/Documents/AI/AI-LINTI/LLM - KDnuggets/app.py\", line 70, in <module>\n",
      "    get_ipython().system(' jupyter nbconvert --to script app.ipynb')\n",
      "    ^^^^^^^^^^^\n",
      "NameError: name 'get_ipython' is not defined\n",
      "/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "2024-07-09 18:39:54.092 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 589, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"/Users/juanfazzano/Documents/AI/AI-LINTI/LLM - KDnuggets/app.py\", line 62, in <module>\n",
      "    generate_response(text)\n",
      "  File \"/Users/juanfazzano/Documents/AI/AI-LINTI/LLM - KDnuggets/app.py\", line 49, in generate_response\n",
      "    st.info(llm(input_text))\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/langchain_core/language_models/llms.py\", line 1192, in __call__\n",
      "    self.generate(\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/langchain_core/language_models/llms.py\", line 882, in generate\n",
      "    output = self._generate_helper(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/langchain_core/language_models/llms.py\", line 740, in _generate_helper\n",
      "    raise e\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/langchain_core/language_models/llms.py\", line 727, in _generate_helper\n",
      "    self._generate(\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/langchain_community/llms/openai.py\", line 464, in _generate\n",
      "    response = completion_with_retry(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/langchain_community/llms/openai.py\", line 119, in completion_with_retry\n",
      "    return llm.client.create(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/openai/resources/completions.py\", line 528, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanfazzano/miniconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    }
   ],
   "source": [
    "### pasar de .ipynb a .py y ejecutar la aplicaciÃ³n\n",
    "\n",
    "! jupyter nbconvert --to script app.ipynb\n",
    "! streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b6ea0-6975-4ef5-8824-3b4006b3441a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
